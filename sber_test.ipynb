{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrF3iC3Zd0+BotuSf4EjlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2haed/sber_test/blob/main/sber_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aExd8fgMRPOO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(filename) -> pd.DataFrame:\n",
        "    with open(f'data/{filename}.csv', 'r', encoding='utf-8') as file:\n",
        "        data_frame = pd.read_csv(file, index_col=0, low_memory=False) * 1\n",
        "        return data_frame"
      ],
      "metadata": {
        "id": "PV82dRvxRh_X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_person_data(df) -> pd.DataFrame:\n",
        "    normal_data = df[['person_id']]\n",
        "    to_normalize = df.drop(['date', 'person_id'], axis=1).apply(lambda x: pd.factorize(x)[0])\n",
        "    to_normalize = (to_normalize - to_normalize.min()) / (to_normalize.max() - to_normalize.min())\n",
        "    df = pd.concat([normal_data, to_normalize], axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "dqx0njaFRjjm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_action_data(df) -> pd.DataFrame:\n",
        "    normal_data = df[['person_id', 'action_type', 'action_id']]\n",
        "    to_normalize = df.drop(['person_id', 'date', 'action_type', 'action_id'], axis=1).apply(\n",
        "        lambda x: pd.factorize(x)[0])\n",
        "    to_normalize = (to_normalize - to_normalize.min()) / (to_normalize.max() - to_normalize.min())\n",
        "    df = pd.concat([normal_data, to_normalize], axis=1)\n",
        "    df = pd.get_dummies(df, columns=[\"action_type\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "TAKACsUSRjmw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_redundant_pairs(df: pd.DataFrame) -> set:\n",
        "    pairs_to_drop = set()\n",
        "    cols = df.columns\n",
        "    for i in range(0, df.shape[1]):\n",
        "        for j in range(0, i + 1):\n",
        "            pairs_to_drop.add((cols[i], cols[j]))\n",
        "    return pairs_to_drop"
      ],
      "metadata": {
        "id": "nx1lNDwdRjog"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corr_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.corr().abs()"
      ],
      "metadata": {
        "id": "4-X8kuAPRjqf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_abs_correlations(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
        "    au_corr = df.corr().abs().unstack()\n",
        "    labels_to_drop = get_redundant_pairs(df)\n",
        "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
        "    return au_corr[0:n]"
      ],
      "metadata": {
        "id": "EqQDzrtjRjsj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = normalize_action_data(get_data('action_test'))\n",
        "train_df = normalize_action_data(get_data('action_train'))\n",
        "person_df = normalize_person_data(get_data('person'))"
      ],
      "metadata": {
        "id": "8hz2hBhERoJ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.merge(test_df, person_df, on='person_id', suffixes=('_action', '_person')).set_index(\n",
        "    ['action_id', 'person_id'])\n",
        "train_df = pd.merge(train_df, person_df, on='person_id', suffixes=('_action', '_person')).set_index(\n",
        "    ['action_id', 'person_id'])"
      ],
      "metadata": {
        "id": "kLQZ29kKRoLY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(['result'], axis=1)\n",
        "y_train = train_df.result\n",
        "X_test = test_df"
      ],
      "metadata": {
        "id": "BzsKTPjURoNx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)\n",
        "y_train = np.array(y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ubrIMSoRoQP",
        "outputId": "4e36b26f-aa12-44f4-93a0-19612c18409f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.5, 0.5, ..., 0.5, 0.5, 0. ])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train_scaled, y_train)\n",
        "rfc.score(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bukN-VbWRoRP",
        "outputId": "27f2f1e5-bfe7-4fd4-d79b-b8e23f954c9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9843816772562214"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feats = {}\n",
        "for feature, importance in zip(train_df.columns, rfc.feature_importances_):\n",
        "    feats[feature] = importance\n",
        "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})\n",
        "importances = importances.sort_values(by='Gini-Importance', ascending=False)\n",
        "importances = importances.reset_index()\n",
        "importances = importances.rename(columns={'index': 'Features'})\n",
        "sns.set(font_scale = 5)\n",
        "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.7)\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(30,15)\n",
        "sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')\n",
        "plt.xlabel('Importance', fontsize=25, weight = 'bold')\n",
        "plt.ylabel('Features', fontsize=25, weight = 'bold')\n",
        "plt.title('Feature Importance', fontsize=25, weight = 'bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xQfrBkZiRoSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "n_estimators = [300, 500, 700]\n",
        "max_features = ['sqrt']\n",
        "max_depth = [2, 3, 7, 11, 15]\n",
        "min_samples_split = [2, 3, 4, 22, 23, 24]\n",
        "min_samples_leaf = [2, 3, 4, 5, 6, 7]\n",
        "grid_search_cv_parameters = {'n_estimators': n_estimators,\n",
        "                             'max_features': max_features,\n",
        "                             'max_depth': max_depth,\n",
        "                             'min_samples_split': min_samples_split,\n",
        "                             'min_samples_leaf': min_samples_leaf,\n",
        "                             }\n",
        "grid_search_cv_clf = GridSearchCV(clf, grid_search_cv_parameters, cv=5, error_score='raise')\n"
      ],
      "metadata": {
        "id": "ehlN1PvSRoUB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
        "max_features = ['log2', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(start=1, stop=15, num=15)]\n",
        "min_samples_split = [int(x) for x in np.linspace(start=2, stop=50, num=10)]\n",
        "min_samples_leaf = [int(x) for x in np.linspace(start=2, stop=50, num=10)]\n",
        "param_dist = {'n_estimators': n_estimators,\n",
        "              'max_features': max_features,\n",
        "              'max_depth': max_depth,\n",
        "              'min_samples_split': min_samples_split,\n",
        "              'min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "random_search_clf = RandomizedSearchCV(clf,\n",
        "                                       param_dist,\n",
        "                                       n_iter=100,\n",
        "                                       cv=3,\n",
        "                                       verbose=1,\n",
        "                                       n_jobs=-1,\n",
        "                                       random_state=0,\n",
        "                                       error_score='raise')"
      ],
      "metadata": {
        "id": "vW_fED_5gzWG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMpEwj_eDxsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_cv_clf.fit(X_train_scaled, y_train)\n",
        "# random_search_clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "SD5lSE305nOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_grid_clf = grid_search_cv_clf.best_estimator_\n",
        "best_grid_clf.best_params_\n",
        "best_random_clf = random_search_clf.best_estimator_\n",
        "best_random_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "AVzeW-5b5nP8",
        "outputId": "e0d35e0e-e9e6-430b-b650-119e8a122f42"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f1570379a08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_grid_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_cv_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_random_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_best_grid_clf = best_grid_clf.predict(X_test_scaled)\n",
        "y_pred_best_random_clf = clf.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "3sLYk1Pk5nRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_baseline_best_clf = pd.DataFrame(confusion_matrix(y_test, y_pred_best_grid_clf),\n",
        "                                             index=['actual 0', 'actual 1'],\n",
        "                                             columns=['predicted 0', 'predicted 1'])\n",
        "print(conf_matrix_baseline_best_clf)\n",
        "print('Baseline Random Forest recall score Best classifier', recall_score(y_test, y_pred_best_grid_clf))\n",
        "\n",
        "conf_matrix_baseline_best_random_search_clf = pd.DataFrame(confusion_matrix(y_test, y_pred_best_random_clf),\n",
        "                                                           index=['actual 0', 'actual 1'],\n",
        "                                                           columns=['predicted 0', 'predicted 1'])\n",
        "print(conf_matrix_baseline_best_random_search_clf)\n",
        "print('Baseline Random Forest recall score regular classifier', recall_score(y_test, y_pred_best_random_clf))"
      ],
      "metadata": {
        "id": "x5Eri6DC5nTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zwb-hhxt5nVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}