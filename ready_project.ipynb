{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2haed/sber_test/blob/main/ready_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "NKWcQaYhf_-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs clone 'https://github.com/2haed/sber_test' repo"
      ],
      "metadata": {
        "id": "mB5dnEEzf_8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aExd8fgMRPOO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "from sklearn.metrics import recall_score, precision_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(filename) -> pd.DataFrame:\n",
        "    with open(f'repo/data/{filename}.csv', 'r', encoding='utf-8') as file:\n",
        "        data_frame = pd.read_csv(file, index_col=0, low_memory=False) * 1\n",
        "        return data_frame"
      ],
      "metadata": {
        "id": "PV82dRvxRh_X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_person_data(df) -> pd.DataFrame:\n",
        "    normal_data = df[['person_id']]\n",
        "    to_normalize = df.drop(['date', 'person_id'], axis=1).apply(lambda x: pd.factorize(x)[0])\n",
        "    to_normalize = (to_normalize - to_normalize.min()) / (to_normalize.max() - to_normalize.min())\n",
        "    df = pd.concat([normal_data, to_normalize], axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "dqx0njaFRjjm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_action_data(df) -> pd.DataFrame:\n",
        "    normal_data = df[['person_id', 'action_type', 'action_id']]\n",
        "    to_normalize = df.drop(['person_id', 'date', 'action_type', 'action_id'], axis=1).apply(\n",
        "        lambda x: pd.factorize(x)[0])\n",
        "    to_normalize = (to_normalize - to_normalize.min()) / (to_normalize.max() - to_normalize.min())\n",
        "    df = pd.concat([normal_data, to_normalize], axis=1)\n",
        "    df = pd.get_dummies(df, columns=[\"action_type\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "TAKACsUSRjmw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_redundant_pairs(df: pd.DataFrame) -> set:\n",
        "    pairs_to_drop = set()\n",
        "    cols = df.columns\n",
        "    for i in range(0, df.shape[1]):\n",
        "        for j in range(0, i + 1):\n",
        "            pairs_to_drop.add((cols[i], cols[j]))\n",
        "    return pairs_to_drop"
      ],
      "metadata": {
        "id": "hxzPEQZlgX6n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_abs_correlations(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
        "    au_corr = df.corr().abs().unstack()\n",
        "    labels_to_drop = get_redundant_pairs(df)\n",
        "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
        "    return au_corr[0:n]"
      ],
      "metadata": {
        "id": "cAIZs1ahgYBg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_importances(train_df: pd.DataFrame, rfc: RandomForestClassifier) -> None:\n",
        "    feats = {}\n",
        "    for feature, importance in zip(train_df.columns, rfc.feature_importances_):\n",
        "        feats[feature] = importance\n",
        "    importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})\n",
        "    importances = importances.sort_values(by='Gini-Importance', ascending=False)\n",
        "    importances = importances.reset_index()\n",
        "    importances = importances.rename(columns={'index': 'Features'})\n",
        "    sns.set(font_scale=5)\n",
        "    sns.set(style=\"whitegrid\", color_codes=True, font_scale=1.7)\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(30, 15)\n",
        "    sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')\n",
        "    plt.xlabel('Importance', fontsize=25, weight='bold')\n",
        "    plt.ylabel('Features', fontsize=25, weight='bold')\n",
        "    plt.title('Feature Importance', fontsize=25, weight='bold')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EMEiTJRmhMQx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = normalize_action_data(get_data('action_test'))\n",
        "train = normalize_action_data(get_data('action_train'))\n",
        "person = normalize_person_data(get_data('person'))"
      ],
      "metadata": {
        "id": "8hz2hBhERoJ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.merge(train, person, on='person_id', suffixes=('_action', '_person')).set_index(\n",
        "    ['action_id', 'person_id'])\n",
        "test_df = pd.merge(test, person, on='person_id', suffixes=('_action', '_person')).set_index(\n",
        "    ['action_id', 'person_id'])"
      ],
      "metadata": {
        "id": "kLQZ29kKRoLY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели на тестовом дата сете"
      ],
      "metadata": {
        "id": "NfWr4hE-kCSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop(['result'], axis=1)\n",
        "y = train_df.result\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "RXPMnLUCgyq0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель случайного леса до очистки данных для сравнения\n",
        "\n",
        "Получение гиперпараметров с помощью RandomizedSearchCV для RandomForestClassifier (**Очень долгий процесс**, результат уже получен в pickle формате)\n"
      ],
      "metadata": {
        "id": "XxonJHPro3J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "n_estimators = [int(x) for x in np.linspace(start=500, stop=1000, num=100)]\n",
        "max_features = ['log2', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(start=2, stop=20, num=15)]\n",
        "min_samples_split = [int(x) for x in np.linspace(start=2, stop=20, num=10)]\n",
        "min_samples_leaf = [int(x) for x in np.linspace(start=2, stop=20, num=10)]\n",
        "bootstrap = [True, False]\n",
        "param_dist = {'n_estimators': n_estimators,\n",
        "              'max_features': max_features,\n",
        "              'max_depth': max_depth,\n",
        "              'min_samples_split': min_samples_split,\n",
        "              'min_samples_leaf': min_samples_leaf,\n",
        "              'bootstrap': bootstrap}\n",
        "random_search_clf = RandomizedSearchCV(clf,\n",
        "                                       param_dist,\n",
        "                                       cv=3,\n",
        "                                       verbose=3,\n",
        "                                       n_jobs=-1,\n",
        "                                       random_state=0)\n",
        "random_search_clf.fit(X_train_scaled, y_train)\n",
        "best_clf = random_search_clf.best_estimator_\n",
        "with open(\"repo/data/models/forest_randomized_search_cv_best_estimator.pkl\", \"wb\") as pickle_file:\n",
        "    pickle.dump(best_clf, pickle_file)"
      ],
      "metadata": {
        "id": "5VGR0qY-o0Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('repo/data/models/forest_randomized_search_cv_best_estimator.pkl', 'rb') as pickle_file:\n",
        "    forest_clf = pickle.load(pickle_file)\n",
        "\n",
        "y_prob_forest = forest_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred_forest = forest_clf.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "4BlF0ODKmV5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель Cat Boost после очистки"
      ],
      "metadata": {
        "id": "KF9Bq4yhnHdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = X_train.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
        "X_train.drop(to_drop, axis=1, inplace=True)\n",
        "X_test.drop(to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "A_x_NViEgp0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "2ubrIMSoRoQP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train_scaled, y_train)\n",
        "rfc.score(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "9Q4G11NLvtU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_importances(train_df, rfc)"
      ],
      "metadata": {
        "id": "xQfrBkZiRoSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получение гиперпараметров с помощью GridSearchCV для CatBoostClassifier \n",
        "(**Очень долгий процесс**, результат уже получен в pickle формате)"
      ],
      "metadata": {
        "id": "HkV2xSoNjlnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = CatBoostClassifier(early_stopping_rounds=200, task_type='GPU', loss_function='MultiClass')\n",
        "\n",
        "params = {'depth': [4, 6, 10],\n",
        "          'learning_rate': [0.05, 0.1, 0.15],\n",
        "          'l2_leaf_reg': [1, 4, 9],\n",
        "          'iterations': [10, 100, 300, 500, 1000],\n",
        "          'early_stopping_rounds': [1000],\n",
        "          'loss_function': ['MultiClass'],\n",
        "          }\n",
        "grid_search_cv_clf = GridSearchCV(clf, \n",
        "                                  param_grid=params, \n",
        "                                  scoring=\"accuracy\", \n",
        "                                  cv=3, \n",
        "                                  verbose=3)\n",
        "grid_search_cv_clf.fit(X_train_scaled, y_train)\n",
        "best_clf = grid_search_cv_clf.best_estimator_\n",
        "with open(\"repo/data/models/catboost_randomized_search_cv.pkl\", \"wb\") as pickle_file:\n",
        "    pickle.dump(best_clf, pickle_file)"
      ],
      "metadata": {
        "id": "de9pJYdcjHKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('repo/data/models/catboost_randomized_search_cv.pkl', 'rb') as pickle_file:\n",
        "    catboost_clf = pickle.load(pickle_file)\n",
        "best_params = catboost_clf.get_params()\n",
        "y_prob_catboost = catboost_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred_catboost = catboost_clf.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "3sLYk1Pk5nRr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_random_forest_best_clf = pd.DataFrame(confusion_matrix(y_test, y_pred_forest),\n",
        "                                             index=['actual F', 'actual T'],\n",
        "                                             columns=['predicted F', 'predicted T'])\n",
        "print(conf_matrix_random_forest_best_clf)\n",
        "print(f'Random Forest recall score Best classifier, {recall_score(y_test, y_pred_forest)},\\nCat Boost precision score regular classifier {precision_score(y_test, y_pred_forest)}')\n",
        "\n",
        "conf_matrix_cat_boost_best_clf = pd.DataFrame(confusion_matrix(y_test, y_pred_catboost),\n",
        "                                                           index=['actual F', 'actual T'],\n",
        "                                                           columns=['predicted F', 'predicted T'])\n",
        "print(conf_matrix_cat_boost_best_clf)\n",
        "print(f'Cat Boost recall score regular classifier, {recall_score(y_test, y_pred_catboost)},\\nCat Boost precision score regular classifier {precision_score(y_test, y_pred_catboost)}')"
      ],
      "metadata": {
        "id": "x5Eri6DC5nTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Жертвуя точностью recall метрики, мы получаем хорошее увеличение в precision score в моделе Cat boost по сравнению с обычным случайным лесом"
      ],
      "metadata": {
        "id": "uVYFcWQr2d6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fprs_forest, tprs_forest, thr_forest = roc_curve(y_test, y_pred_forest)\n",
        "plt.plot(fprs_forest, tprs_forest, marker='o')\n",
        "plt.ylim([0, 1.1]);plt.xlim([0,1.1])\n",
        "plt.xlabel('FPR');plt.ylabel('TPR')\n",
        "plt.title('ROC_curve_forest')"
      ],
      "metadata": {
        "id": "mBHX9bOanTO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fprs_cat_boost, tprs_cat_boost, thr_cat_boost = roc_curve(y_test, y_pred_catboost)\n",
        "plt.plot(fprs_cat_boost, tprs_cat_boost, marker='o')\n",
        "plt.ylim([0, 1.1]);plt.xlim([0,1.1])\n",
        "plt.xlabel('FPR');plt.ylabel('TPR')\n",
        "plt.title('ROC_curve_cat_boost')"
      ],
      "metadata": {
        "id": "p2h-T9GrpZBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "По метрике ROC кривой, модель cat_boost оказалась точнее"
      ],
      "metadata": {
        "id": "1xp1GkIw2Pmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь можно обучать на полном тренировочном дата сете и получать итоговые результаты на тестовом"
      ],
      "metadata": {
        "id": "C9jn10c1q3BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(['result'], axis=1)\n",
        "X_test = test_df\n",
        "y_train = train_df.result"
      ],
      "metadata": {
        "id": "lOYuwqvMiTk3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "Zwb-hhxt5nVP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = CatBoostClassifier(**best_params)\n",
        "clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "MYkhbRvmrDFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "result = pd.Series(y_prob)\n",
        "result.name = 'result'\n",
        "final_df = pd.concat([test.action_id, result], axis=1)"
      ],
      "metadata": {
        "id": "LD2NniyKr5wU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('repo/data/ready_catboost.csv', encoding='utf-8', index=False, columns=['action_id', 'result'])"
      ],
      "metadata": {
        "id": "zGMIxvd5sBQ_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(final_df)"
      ],
      "metadata": {
        "id": "4H7oVta-0jzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}